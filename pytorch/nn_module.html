
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>NN Module Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="subclassing_nn_module.html" />
    
    
    <link rel="prev" href="neural_network.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../markdown_math_syntax.html">
            
                <a href="../markdown_math_syntax.html">
            
                    
                    Markdown Math Syntax
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../gradient_descent/gradient_descent.html">
            
                <a href="../gradient_descent/gradient_descent.html">
            
                    
                    Gradient Descent
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../gradient_descent/more_about_gradient_descent.html">
            
                <a href="../gradient_descent/more_about_gradient_descent.html">
            
                    
                    More about Gradient Descent
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../gradient_descent/new_optimization.html">
            
                <a href="../gradient_descent/new_optimization.html">
            
                    
                    New Optimazation
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../classification/classification.html">
            
                <a href="../classification/classification.html">
            
                    
                    Classification
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../logistic_regression/logistic_regression.html">
            
                <a href="../logistic_regression/logistic_regression.html">
            
                    
                    Logistic Regression
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../logistic_regression/lrcode.html">
            
                <a href="../logistic_regression/lrcode.html">
            
                    
                    LRCode
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../deep_learning/deep_learning.html">
            
                <a href="../deep_learning/deep_learning.html">
            
                    
                    Deep Learing
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../deep_learning/tips_for_deep_learning.html">
            
                <a href="../deep_learning/tips_for_deep_learning.html">
            
                    
                    Tips for Deep Learning
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="pytorch.html">
            
                <a href="pytorch.html">
            
                    
                    Pytorch
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="main_mdel_introduction.html">
            
                <a href="main_mdel_introduction.html">
            
                    
                    Main Model Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="three_kinds_of_data.html">
            
                <a href="three_kinds_of_data.html">
            
                    
                    three kinds of data
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.3" data-path="real_data_representaion.html">
            
                <a href="real_data_representaion.html">
            
                    
                    real world data representation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.4" data-path="walking_through_a_learning_algorithm_from_scratch.html">
            
                <a href="walking_through_a_learning_algorithm_from_scratch.html">
            
                    
                    The mechanics of learning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.5" data-path="autograd.html">
            
                <a href="autograd.html">
            
                    
                    Backpropagate all things
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.6" data-path="training_validation_overfitting.html">
            
                <a href="training_validation_overfitting.html">
            
                    
                    Training, validation, and overfitting
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.7" data-path="neural_network.html">
            
                <a href="neural_network.html">
            
                    
                    Neural Network
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.7.8" data-path="nn_module.html">
            
                <a href="nn_module.html">
            
                    
                    NN Module
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.9" data-path="subclassing_nn_module.html">
            
                <a href="subclassing_nn_module.html">
            
                    
                    Subclassing NN Module
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.10" data-path="pre-trained_network.html">
            
                <a href="pre-trained_network.html">
            
                    
                    Pre-trained Network
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.11" data-path="image_classification.html">
            
                <a href="image_classification.html">
            
                    
                    Image Classification
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.12" data-path="problem_set_of_pytorch.html">
            
                <a href="problem_set_of_pytorch.html">
            
                    
                    Problem Set of PyTorch
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="../convolutional_neural_network/cnn.html">
            
                <a href="../convolutional_neural_network/cnn.html">
            
                    
                    Convolutional Neural network
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.1" data-path="../convolutional_neural_network/cnn_network_structure.html">
            
                <a href="../convolutional_neural_network/cnn_network_structure.html">
            
                    
                    CNN Network Structure
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.2" data-path="../convolutional_neural_network/common_cnn.html">
            
                <a href="../convolutional_neural_network/common_cnn.html">
            
                    
                    Common CNN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.3" data-path="../convolutional_neural_network/cnn_aplication.html">
            
                <a href="../convolutional_neural_network/cnn_aplication.html">
            
                    
                    CNN Aplication
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="../graph_neural_network/graph_neural_network.html">
            
                <a href="../graph_neural_network/graph_neural_network.html">
            
                    
                    Graph Neural Network
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.9.1" data-path="../graph_neural_network/introduce_to_graph_neural_network.html">
            
                <a href="../graph_neural_network/introduce_to_graph_neural_network.html">
            
                    
                    Introduce to Graph Neural Network
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.2" data-path="../graph_neural_network/Spatial_based_gnn.html">
            
                <a href="../graph_neural_network/Spatial_based_gnn.html">
            
                    
                    Spatial-based GNN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.3" data-path="../graph_neural_network/Spectral_based_gnn.html">
            
                <a href="../graph_neural_network/Spectral_based_gnn.html">
            
                    
                    Spectral_based_gnn
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="../recurrent_neural_network/recurrent_neural_network.html">
            
                <a href="../recurrent_neural_network/recurrent_neural_network.html">
            
                    
                    Recurrent Neural Network
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.1" data-path="../recurrent_neural_network/recursive_structure.html">
            
                <a href="../recurrent_neural_network/recursive_structure.html">
            
                    
                    Recursive Structure
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.11" data-path="../semi_supervised/semi_supervised.html">
            
                <a href="../semi_supervised/semi_supervised.html">
            
                    
                    Semi-supervised
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12" data-path="../word_embedding/word_embedding.html">
            
                <a href="../word_embedding/word_embedding.html">
            
                    
                    Word Embedding
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.13" data-path="../explainable_machine_learning/explainable_machine_learning.html">
            
                <a href="../explainable_machine_learning/explainable_machine_learning.html">
            
                    
                    Explainable Machine Learning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.14" data-path="../attack_ml_models/attack_ml_models.html">
            
                <a href="../attack_ml_models/attack_ml_models.html">
            
                    
                    Attack ML Models
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.14.1" data-path="../attack_ml_models/attack_image_and_audio.html">
            
                <a href="../attack_ml_models/attack_image_and_audio.html">
            
                    
                    Attack image and audio
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.15" data-path="../network_compression/network_compression.html">
            
                <a href="../network_compression/network_compression.html">
            
                    
                    Network Compression
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.15.1" data-path="../network_compression/knowledge_distillation.html">
            
                <a href="../network_compression/knowledge_distillation.html">
            
                    
                    Knowledge Distillation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.2" data-path="../network_compression/network_pruning.html">
            
                <a href="../network_compression/network_pruning.html">
            
                    
                    Network Pruning
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.16" data-path="../transformer/transformer.html">
            
                <a href="../transformer/transformer.html">
            
                    
                    Transformer
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.16.1" data-path="../transformer/variant_of_transformers.html">
            
                <a href="../transformer/variant_of_transformers.html">
            
                    
                    Variant of Transformers
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.17" data-path="../conditional_generation_by_RNN_&_Attention/conditional_generation_by_RNN_&_Attention.html">
            
                <a href="../conditional_generation_by_RNN_&_Attention/conditional_generation_by_RNN_&_Attention.html">
            
                    
                    Conditional Generation by RNN & Attention
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.18" data-path="../unsupervised_learning/unsupervised_learning.html">
            
                <a href="../unsupervised_learning/unsupervised_learning.html">
            
                    
                    Unsupervised Learning
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.18.1" data-path="../unsupervised_learning/dimension_reduction.html">
            
                <a href="../unsupervised_learning/dimension_reduction.html">
            
                    
                    Dimension Reduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.18.2" data-path="../unsupervised_learning/neighbor_embedding.html">
            
                <a href="../unsupervised_learning/neighbor_embedding.html">
            
                    
                    Neighbor Embedding
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.18.3" data-path="../unsupervised_learning/deep_auto_encoder.html">
            
                <a href="../unsupervised_learning/deep_auto_encoder.html">
            
                    
                    Deep Auto-encoder
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.19" data-path="../bert_and_its_family/bert_and_its_family.html">
            
                <a href="../bert_and_its_family/bert_and_its_family.html">
            
                    
                    Bert and its Family
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.19.1" data-path="../bert_and_its_family/bert.html">
            
                <a href="../bert_and_its_family/bert.html">
            
                    
                    Bert
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.20" data-path="../nlp/natural_language_processing.html">
            
                <a href="../nlp/natural_language_processing.html">
            
                    
                    Natual Language Processing
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.20.1" data-path="../nlp/introduction.html">
            
                <a href="../nlp/introduction.html">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.21" data-path="../anomaly_detection/anomaly_detection.html">
            
                <a href="../anomaly_detection/anomaly_detection.html">
            
                    
                    Anomaly Detection
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >NN Module</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="nn-module">NN Module</h1>
<p>PyTorch has a whole submodule dedicated to neural networks: <code>torch.nn</code>. This submodule contains the building blocks needed to create all sorts of  neural network architectures. Those building blocks are called modules in PyTorch parlance (and layersin other frameworks)  </p>
<p>A PyTorch module is a Python class deriving from the <code>nn.Module</code> base class. A <code>Module</code> can have one or more Parameter instances as attributes, which are tensors whose values are optimized during the training process.</p>
<p><strong>NOTE</strong> The submodules must be top-level attributes, not buried inside list or dict instances! Otherwise, the optimizer won&#x2019;t be able to locate the submodules (and, hence, their parameters). For situations in which your model requires a list or dict of submodules, PyTorch  provides <code>nn.ModuleList</code> and <code>nn.ModuleDict</code>.</p>
<p>All PyTorch-provided subclasses of <code>nn.Module</code> have their <code>call</code> method defined, which allows you to instantiate an <code>nn.Linear</code> and call it as though it were a function.</p>
<h2 id="torchnnlinear">Torch.nn.Linear</h2>
<p><code>CLASS torch.nn.Linear(in_features, out_features, bias=True)</code></p>
<p><code>nn.Linear</code>, a subclass of <code>nn.Module</code>, which applies an affine transformation to its input (via the parameter attributes <code>weight</code> and <code>bias</code>)</p>
<p><em>Parameters</em> :</p>
<ul>
<li>in_features &#x2013;  the number of input features ,or say, size of each input sample(or tensor) (i.e. size of x)</li>
<li>out_features &#x2013; the  number  of  output  features, or say, size of each output sample(or tensor) (i.e. size of y)</li>
<li>bias &#x2013; whether the linear model includes a bias. If set to False, the layer will not learn an additive bias. Default: True  </li>
</ul>
<p>Note that the weights <code>W</code> have shape <code>(out_features, in_features)</code> and biases <code>b</code> have shape <code>(out_features)</code>. They are initialized randomly and can be changed later (e.g. during the training of a Neural Network they are updated by some optimization algorithm).</p>
<p>Calling an instance of <code>nn.Module</code> with a set of arguments ends up calling a method named <code>forward</code> with the same arguments. The <code>forward</code> method executes the forward computation; <code>call</code> does other rather important chores before and after calling <code>forward</code>. So it&#x2019;s technically possible to call forward directly, and it produces the same output as call, but it <strong>shouldn&#x2019;t be done</strong> from user code.</p>
<p><code>weight</code>, which obtains from <code>nn.Module</code>, has the shape of <code>[out_features,in_features]</code>. </p>
<ul>
<li><code>out_features</code> is the number of network neurons in this layer.</li>
<li><code>in_features</code> is the number of neurons in the previous network layer.</li>
</ul>
<p><code>bias</code>, which also comes from <code>nn.Module</code>, has the shape of <code>[out_features]</code></p>
<p><strong>Note</strong>  To accommodate multiple samples, modules expect the zeroth dimension of the input to be the number of samples in the batch. You can provide an input tensor of size <code>B x Nin</code>, where B is the size of the batch and Nin thenumber of input features.</p>
<h2 id="optimizer">Optimizer</h2>
<pre><code class="lang-python">linear_model = nn.Linear(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)
optimizer = optim.SGD(linear_model.parameters(),lr=<span class="hljs-number">1e-2</span>)
</code></pre>
<p>You can ask any <code>nn.Module</code> for a list of parameters owned byit or any of its submodules by using the <code>parameters</code> method. This call recurses into submodules defined in the module&#x2019;s <code>init</code> constructor and returns a flat list of all parameters encountered.</p>
<p>Now you don&#x2019;t pass params explicitly to model because the <code>model</code> itself holds its <code>Parameters</code> internally.Loss functions in nn are stillsubclasses  of nn.Module,  so  create  an  instance  and  call it  as  a  function. As following :</p>
<p><strong>Demo of NN Module</strong></p>
<pre><code class="lang-python"><span class="hljs-comment"># train </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">training_loop</span><span class="hljs-params">(n_epochs,optimizer,model,loss_fn,t_un_train,t_un_val,t_c_train,t_c_val)</span>:</span>
    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>,n_epochs):
        t_p_train = model(t_un_train)
        loss_train = loss_fn(t_p_train,t_c_train)

        t_p_val = model(t_un_val)
        loss_val = loss_fn(t_p_val,t_c_val)

        optimizer.zero_grad()
        loss_train.backward()
        optimizer.step()

        <span class="hljs-keyword">if</span> epoch == <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> epoch % <span class="hljs-number">200</span> == <span class="hljs-number">0</span>:
            print(<span class="hljs-string">&quot;Epoch {}, Train Loss {}, Validation Loss {}&quot;</span>.format(epoch,float(loss_train),float(loss_val)))

linear_model = nn.Linear(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)
optimizer = optim.SGD(linear_model.parameters(),lr=<span class="hljs-number">1e-2</span>)
training_loop(
    n_epochs = <span class="hljs-number">3000</span>,
    optimizer = optimizer,
    model = linear_model,
    loss_fn = nn.MSELoss(),
    t_un_train = t_un_train,
    t_un_val = t_un_val,
    t_c_train = t_c_train,
    t_c_val = t_c_val
)
print()
print(f<span class="hljs-string">&quot;weight : {linear_model.weight}&quot;</span>)
print(f<span class="hljs-string">&quot;bias : {linear_model.bias}&quot;</span>)
</code></pre>
<h2 id="hidden-layer">Hidden Layer</h2>
<p><code>nn</code> provides a simple way to concatenate modules through the <code>nn.Sequential</code> container.</p>
<pre><code class="lang-python">seq_model = nn.Sequential(
    nn.Linear(<span class="hljs-number">1</span>,<span class="hljs-number">13</span>),
    nn.Tanh(),
    nn.Linear(<span class="hljs-number">13</span>,<span class="hljs-number">1</span>)
)
<span class="hljs-comment"># out of seq_model:</span>
<span class="hljs-comment"># Sequential(</span>
<span class="hljs-comment">#   (0): Linear(in_features=1, out_features=13, bias=True)</span>
<span class="hljs-comment">#   (1): Tanh()</span>
<span class="hljs-comment">#   (2): Linear(in_features=13, out_features=1, bias=True)</span>
<span class="hljs-comment"># )</span>
</code></pre>
<p>The result is a model that takes the inputs expected by the first module specified as an argument of <code>nn.Sequential</code>, passes intermediate outputs to subsequent modules, and produces the  output returned by the last module. The model fans  out from 1 input feature to 13 hidden features, passes them through a tanh activation, and linearly combines the resulting 13 numbers into 1 output feature.</p>
<p>Calling <code>model.parameters()</code> collects weight and bias from all modules.</p>
<pre><code class="lang-python">[param.shape <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> seq_model.parameters()]
<span class="hljs-comment"># Out:</span>
<span class="hljs-comment"># [torch.Size([13, 1]), torch.Size([13]), torch.Size([1, 13]), torch.Size([1])]</span>
</code></pre>
<p>After <code>model.backward()</code> iscalled, all parameters are populated with their <code>grad</code>, and then the optimizer updates their values accordingly during  the <code>optimizer.step()</code> call.</p>
<p>Identify parameters by their names. There&#x2019;s a method for that, called <code>named_parameters</code>.</p>
<pre><code class="lang-python"><span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> seq_model.named_parameters():
    print(name, param.shape)
<span class="hljs-comment"># Out:</span>
<span class="hljs-comment"># 0.weight torch.Size([13, 1])</span>
<span class="hljs-comment"># 0.bias torch.Size([13])</span>
<span class="hljs-comment"># 2.weight torch.Size([1, 13])</span>
<span class="hljs-comment"># 2.bias torch.Size([1])</span>
</code></pre>
<p>The name of each module in <code>Sequential</code> is the ordinal with which the module appeared in the arguments.</p>
<p><code>Sequential</code> also accepts an <code>OrderedDict</code> in which you can name each module passed to <code>Sequential</code></p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> OrderedDict

seq_model = nn.Sequential(OrderedDict([
    (<span class="hljs-string">&quot;hidden_linear&quot;</span>,nn.Linear(<span class="hljs-number">1</span>,<span class="hljs-number">8</span>)),
    (<span class="hljs-string">&quot;hidden_activation&quot;</span>,nn.Tanh()),
    (<span class="hljs-string">&quot;output_linear&quot;</span>,nn.Linear(<span class="hljs-number">8</span>,<span class="hljs-number">1</span>))
]))
</code></pre>
<p>You can also get to a particular Parameter by accessing submodules as though they were attributes:</p>
<pre><code class="lang-python">seq_model.output_linear.bias
</code></pre>
<p><strong>Advanced Demo of NN Module</strong></p>
<pre><code class="lang-python"><span class="hljs-comment"># Using neural network rather than fixed linear module as model,such as seq_model</span>
optimizer = optim.SGD(seq_model.parameters(),lr=<span class="hljs-number">1e-3</span>)
training_loop(
    n_epochs = <span class="hljs-number">3000</span>,
    optimizer = optimizer,
    model = seq_model,
    loss_fn = nn.MSELoss(),
    t_un_train = t_un_train,
    t_un_val = t_un_val,
    t_c_train = t_c_train,
    t_c_val = t_c_val
)
print(<span class="hljs-string">&quot;output&quot;</span>,seq_model(t_un_val))
print(<span class="hljs-string">&quot;answer&quot;</span>,t_c_val)
print(<span class="hljs-string">&quot;hidden&quot;</span>,seq_model.hidden_linear.weight.grad)
</code></pre>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="neural_network.html" class="navigation navigation-prev " aria-label="Previous page: Neural Network">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="subclassing_nn_module.html" class="navigation navigation-next " aria-label="Next page: Subclassing NN Module">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"NN Module","level":"1.7.8","depth":2,"next":{"title":"Subclassing NN Module","level":"1.7.9","depth":2,"path":"pytorch/subclassing_nn_module.md","ref":"pytorch/subclassing_nn_module.md","articles":[]},"previous":{"title":"Neural Network","level":"1.7.7","depth":2,"path":"pytorch/neural_network.md","ref":"pytorch/neural_network.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["mathjax","katex"],"pluginsConfig":{"mathjax":{"forceSVG":false,"version":"2.6-latest"},"katex":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"pytorch/nn_module.md","mtime":"2020-07-20T13:54:09.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2020-07-20T14:05:14.223Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

