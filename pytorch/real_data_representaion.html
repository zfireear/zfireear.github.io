
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>real world data representation Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="walking_through_a_learning_algorithm_from_scratch.html" />
    
    
    <link rel="prev" href="three_kinds_of_data.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../markdown_math_syntax.html">
            
                <a href="../markdown_math_syntax.html">
            
                    
                    Markdown Math Syntax
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../gradient_descent/gradient_descent.html">
            
                <a href="../gradient_descent/gradient_descent.html">
            
                    
                    Gradient Descent
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../gradient_descent/more_about_gradient_descent.html">
            
                <a href="../gradient_descent/more_about_gradient_descent.html">
            
                    
                    More about Gradient Descent
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../gradient_descent/new_optimization.html">
            
                <a href="../gradient_descent/new_optimization.html">
            
                    
                    New Optimazation
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../classification/classification.html">
            
                <a href="../classification/classification.html">
            
                    
                    Classification
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../logistic_regression/logistic_regression.html">
            
                <a href="../logistic_regression/logistic_regression.html">
            
                    
                    Logistic Regression
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../logistic_regression/lrcode.html">
            
                <a href="../logistic_regression/lrcode.html">
            
                    
                    LRCode
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../deep_learning/deep_learning.html">
            
                <a href="../deep_learning/deep_learning.html">
            
                    
                    Deep Learing
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../deep_learning/tips_for_deep_learning.html">
            
                <a href="../deep_learning/tips_for_deep_learning.html">
            
                    
                    Tips for Deep Learning
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="pytorch.html">
            
                <a href="pytorch.html">
            
                    
                    Pytorch
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="main_mdel_introduction.html">
            
                <a href="main_mdel_introduction.html">
            
                    
                    Main Model Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="three_kinds_of_data.html">
            
                <a href="three_kinds_of_data.html">
            
                    
                    three kinds of data
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.7.3" data-path="real_data_representaion.html">
            
                <a href="real_data_representaion.html">
            
                    
                    real world data representation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.4" data-path="walking_through_a_learning_algorithm_from_scratch.html">
            
                <a href="walking_through_a_learning_algorithm_from_scratch.html">
            
                    
                    The mechanics of learning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.5" data-path="autograd.html">
            
                <a href="autograd.html">
            
                    
                    Backpropagate all things
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.6" data-path="training_validation_overfitting.html">
            
                <a href="training_validation_overfitting.html">
            
                    
                    Training, validation, and overfitting
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.7" data-path="neural_network.html">
            
                <a href="neural_network.html">
            
                    
                    Neural Network
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.8" data-path="nn_module.html">
            
                <a href="nn_module.html">
            
                    
                    NN Module
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.9" data-path="subclassing_nn_module.html">
            
                <a href="subclassing_nn_module.html">
            
                    
                    Subclassing NN Module
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.10" data-path="pre-trained_network.html">
            
                <a href="pre-trained_network.html">
            
                    
                    Pre-trained Network
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.11" data-path="image_classification.html">
            
                <a href="image_classification.html">
            
                    
                    Image Classification
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.12" data-path="problem_set_of_pytorch.html">
            
                <a href="problem_set_of_pytorch.html">
            
                    
                    Problem Set of PyTorch
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="../convolutional_neural_network/cnn.html">
            
                <a href="../convolutional_neural_network/cnn.html">
            
                    
                    Convolutional Neural network
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.1" data-path="../convolutional_neural_network/cnn_network_structure.html">
            
                <a href="../convolutional_neural_network/cnn_network_structure.html">
            
                    
                    CNN Network Structure
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.2" data-path="../convolutional_neural_network/common_cnn.html">
            
                <a href="../convolutional_neural_network/common_cnn.html">
            
                    
                    Common CNN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.3" data-path="../convolutional_neural_network/cnn_aplication.html">
            
                <a href="../convolutional_neural_network/cnn_aplication.html">
            
                    
                    CNN Aplication
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="../graph_neural_network/graph_neural_network.html">
            
                <a href="../graph_neural_network/graph_neural_network.html">
            
                    
                    Graph Neural Network
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.9.1" data-path="../graph_neural_network/introduce_to_graph_neural_network.html">
            
                <a href="../graph_neural_network/introduce_to_graph_neural_network.html">
            
                    
                    Introduce to Graph Neural Network
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.2" data-path="../graph_neural_network/Spatial_based_gnn.html">
            
                <a href="../graph_neural_network/Spatial_based_gnn.html">
            
                    
                    Spatial-based GNN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.3" data-path="../graph_neural_network/Spectral_based_gnn.html">
            
                <a href="../graph_neural_network/Spectral_based_gnn.html">
            
                    
                    Spectral_based_gnn
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="../recurrent_neural_network/recurrent_neural_network.html">
            
                <a href="../recurrent_neural_network/recurrent_neural_network.html">
            
                    
                    Recurrent Neural Network
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.1" data-path="../recurrent_neural_network/recursive_structure.html">
            
                <a href="../recurrent_neural_network/recursive_structure.html">
            
                    
                    Recursive Structure
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.11" data-path="../semi_supervised/semi_supervised.html">
            
                <a href="../semi_supervised/semi_supervised.html">
            
                    
                    Semi-supervised
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12" data-path="../word_embedding/word_embedding.html">
            
                <a href="../word_embedding/word_embedding.html">
            
                    
                    Word Embedding
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.13" data-path="../explainable_machine_learning/explainable_machine_learning.html">
            
                <a href="../explainable_machine_learning/explainable_machine_learning.html">
            
                    
                    Explainable Machine Learning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.14" data-path="../attack_ml_models/attack_ml_models.html">
            
                <a href="../attack_ml_models/attack_ml_models.html">
            
                    
                    Attack ML Models
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.14.1" data-path="../attack_ml_models/attack_image_and_audio.html">
            
                <a href="../attack_ml_models/attack_image_and_audio.html">
            
                    
                    Attack image and audio
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.15" data-path="../network_compression/network_compression.html">
            
                <a href="../network_compression/network_compression.html">
            
                    
                    Network Compression
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.15.1" data-path="../network_compression/knowledge_distillation.html">
            
                <a href="../network_compression/knowledge_distillation.html">
            
                    
                    Knowledge Distillation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.2" data-path="../network_compression/network_pruning.html">
            
                <a href="../network_compression/network_pruning.html">
            
                    
                    Network Pruning
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.16" data-path="../transformer/transformer.html">
            
                <a href="../transformer/transformer.html">
            
                    
                    Transformer
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.16.1" data-path="../transformer/variant_of_transformers.html">
            
                <a href="../transformer/variant_of_transformers.html">
            
                    
                    Variant of Transformers
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.17" data-path="../conditional_generation_by_RNN_&_Attention/conditional_generation_by_RNN_&_Attention.html">
            
                <a href="../conditional_generation_by_RNN_&_Attention/conditional_generation_by_RNN_&_Attention.html">
            
                    
                    Conditional Generation by RNN & Attention
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.18" data-path="../unsupervised_learning/unsupervised_learning.html">
            
                <a href="../unsupervised_learning/unsupervised_learning.html">
            
                    
                    Unsupervised Learning
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.18.1" data-path="../unsupervised_learning/dimension_reduction.html">
            
                <a href="../unsupervised_learning/dimension_reduction.html">
            
                    
                    Dimension Reduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.18.2" data-path="../unsupervised_learning/neighbor_embedding.html">
            
                <a href="../unsupervised_learning/neighbor_embedding.html">
            
                    
                    Neighbor Embedding
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.18.3" data-path="../unsupervised_learning/deep_auto_encoder.html">
            
                <a href="../unsupervised_learning/deep_auto_encoder.html">
            
                    
                    Deep Auto-encoder
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.19" data-path="../bert_and_its_family/bert_and_its_family.html">
            
                <a href="../bert_and_its_family/bert_and_its_family.html">
            
                    
                    Bert and its Family
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.19.1" data-path="../bert_and_its_family/bert.html">
            
                <a href="../bert_and_its_family/bert.html">
            
                    
                    Bert
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.20" data-path="../nlp/natural_language_processing.html">
            
                <a href="../nlp/natural_language_processing.html">
            
                    
                    Natual Language Processing
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.20.1" data-path="../nlp/introduction.html">
            
                <a href="../nlp/introduction.html">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.21" data-path="../anomaly_detection/anomaly_detection.html">
            
                <a href="../anomaly_detection/anomaly_detection.html">
            
                    
                    Anomaly Detection
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >real world data representation</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="real-world-data-representation">real world data representation</h1>
<p>PyTorch tensors are homogeneous, information in PyTorch is encoded as a number, typically floating-point.</p>
<h2 id="one-hot-encoding">One-hot Encoding</h2>
<p>Achieve one-hot encoding by using the <code>scatter_</code> method, which fills the tensor with values from a source tensor along the indices provided as arguments</p>
<pre><code class="lang-python">target_onehot = torch.zeros(target.shape[<span class="hljs-number">0</span>], <span class="hljs-number">10</span>)
target_onehot.scatter_(<span class="hljs-number">1</span>, target.unsqueeze(<span class="hljs-number">1</span>), <span class="hljs-number">1.0</span>)
</code></pre>
<p>The arguments for <code>scatter_</code> are</p>
<ul>
<li>The dimension along which the following two arguments are specified</li>
<li>A column tensor indicating the indices of the elements to scatter</li>
<li>A tensor containing the elements to scatter or a single scalar to scatter(1,in this case)</li>
</ul>
<p>The second argument of <code>scatter_</code>, the index tensor, is required to have the same number of dimensions as the tensor you scatter into. Because target_onehot has two dimensions(such as 4898x10),  you need to add an extra dummy dimension to target by using unsqueeze.unsqueeze adds a singleton dimension, without changing its contents. No  elements were added(That is, you accessed the first element of target as target[0] and the first element of its unsqueezed counterpart as target_unsqueezed[0,0])</p>
<h2 id="tensor-api">Tensor API</h2>
<p>use the <code>torch.le</code> function to determine which rows in target correspond to a score less than or equal </p>
<pre><code class="lang-python">bad_indexes = torch.le(target, <span class="hljs-number">3</span>)
</code></pre>
<h2 id="advanced-indexing">Advanced Indexing</h2>
<p>use a binary tensor to index the data tensor.This tensor essentially filters data to be only items (or rows) that correspond to 1 in the indexing  tensor.</p>
<pre><code class="lang-python">bad_data = data[bad_indexes]
</code></pre>
<h2 id="tips-and-tricks">Tips and tricks</h2>
<pre><code class="lang-python"><span class="hljs-keyword">for</span> i, args <span class="hljs-keyword">in</span> enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):    
    print(<span class="hljs-string">&apos;{:2} {:20} {:6.2f} {:6.2f} {:6.2f}&apos;</span>.format(i, *args))
</code></pre>
<ol>
<li><code>zip()</code> is to map the similar index of multiple containers so that they can be used just using as single entity.A zip object, which is an iterator of tuples where the first item in each passed iterator is paired together, and then the second item in each passed iterator are paired together etc. It evaluates the iterables left to right.  </li>
<li>The <code>enumerate()</code> function is used to combine a iterable data object (such as a list, tuple, or string) into an index sequence, which return list data and data subscripts at the same time. It is generally used in a for loop.</li>
</ol>
<h2 id="time-series">Time Series</h2>
<ol>
<li>use <code>torch.sort</code> to order data appropriately.</li>
<li><p>concatenate your matrix to your original data set,  using the <code>cat</code> function</p>
<pre><code class="lang-python"> torch.cat((bikes[:<span class="hljs-number">24</span>], weather_onehot), <span class="hljs-number">1</span>)
</code></pre>
</li>
<li><p>rescaling variables to the <code>[0.0,  1.0]</code> interval or the <code>[-1.0, 1.0]</code> interval is something that you&#x2019;ll want to do for all quantitative variables</p>
<blockquote>
<p>If the variable were drawn from a Gaussian distribution, 68 percent of the samples would sit in the [-1.0, 1.0] interval.</p>
</blockquote>
</li>
</ol>
<h2 id="text-one-hot-encoding">Text One-Hot Encoding</h2>
<p>One-hot encoding is a useful technique for representing categorical data in tensors.<br>one-hot encoded sentence:</p>
<pre><code class="lang-python">line = <span class="hljs-string">&apos;&#x201C;Impossible, Mr. Bennet, impossible, when I am not acquainted with him&apos;</span>

letter_tensor = torch.zeros(len(line),<span class="hljs-number">128</span>)

<span class="hljs-keyword">for</span> i,letter <span class="hljs-keyword">in</span> enumerate(line.lower().strip()):
    letter_index = ord(letter) <span class="hljs-keyword">if</span> ord(letter) &lt; <span class="hljs-number">128</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>
    letter_tensor[i][letter_index] = <span class="hljs-number">1</span>
</code></pre>
<p>one-hot encoded sentens in whole text:</p>
<pre><code class="lang-python">word_list = sorted(set(clean_words(text)))
word2index_dict = {word:i <span class="hljs-keyword">for</span> (i,word) <span class="hljs-keyword">in</span> enumerate(word_list)}

word_tensor = torch.zeros(len(words_in_line),len(word2index_dict))
<span class="hljs-keyword">for</span> i,word <span class="hljs-keyword">in</span> enumerate(words_in_line):
    word_index = word2index_dict[word]
    word_tensor[i][word_index] = <span class="hljs-number">1</span>
</code></pre>
<h2 id="text-embedding">Text Embedding</h2>
<p>Words used in similar contexts map to nearby regions of the embedding.</p>
<h2 id="images">Images</h2>
<pre><code class="lang-python">img_arr = imageio.imread(<span class="hljs-string">&quot;bobby.jpg&quot;</span>)
img_arr.shape
</code></pre>
<p>Img is a NumPy array-like object with three dimensions: two spatial dimensions (width and height) and a third dimension corresponding to the channelsred, green, and blue.</p>
<blockquote>
<p>PyTorch modules that deal with image data require tensors to be laid out as <strong>C x H x W</strong> (channels, height, and width respectively) </p>
</blockquote>
<p>You can use the transpose function to get to an appropriate layout. Given an inputtensor W x H x C, you get to a proper layout by swapping the first and last channels</p>
<pre><code class="lang-python"> img = torch.from_numpy(img_arr)
 out = torch.transpose(img,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>)
</code></pre>
<p>Neural networks exhibit the best training performance when input data ranges from roughly 0 to 1 or &#x2013;1 to 1 (an effect of how their building blocks are defined),Such as compute mean and standard deviation of the input data and scale it  so that the output has zero mean and unit standard deviation.</p>
<h2 id="volumetric-data">Volumetric data</h2>
<p>You have an extra dimension, depth, after the channel dimension, leading to a 5D tensor of shape N x C x D x H x W.<br>Load a sample CT scan by using the volread function in the imageio module.</p>
<pre><code class="lang-python">vol_arr = imageio.volread(dir_path,<span class="hljs-string">&apos;DICOM&apos;</span>)
vol = torch.from_numpy(vol_arr).float()
vol = torch.transpose(vol,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>)
vol = torch.unsqueeze(vol,<span class="hljs-number">0</span>)
</code></pre>
<h2 id="summary">Summary</h2>
<ol>
<li>Neural networks require data to be represented as multidimensional numericaltensors, often 32-bit floating-point</li>
<li>Spreadsheets can be straightforward to convert to tensors</li>
<li>Text or categorical data can be encoded to a one-hot representation throughthe use of dictionaries</li>
<li>Volumetric data is similar to 2D image data,  with the exception of adding athird dimension: depth</li>
<li>Many images have a per-channel bit depth of 8, though 12 and 16 bits per chan-nel are not uncommon. These bit-depths can be stored in a 32-bit floating-pointnumber without loss of precision</li>
<li>Convolutional networks, we would need to lay out the tensor as <code>N x C x L</code>, where <code>N</code> is the number of sounds in a dataset, <code>C</code> the number of channels and <code>L</code> the number of samples in time.</li>
<li>Recurrent networks we mentioned for text, data needs to be laid out as <code>L x N x C</code> - sequence length comes first. Intuitively, this is because the latter architectures take one set of <code>C</code> values at a time</li>
</ol>
<h2 id="audio">Audio</h2>
<p>In order to load the sound we resort to SciPy, specifically <code>scipy.io.wavfile.read</code>, which has the nice property to return data as a NumPy array:</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> scipy.io.wavfile <span class="hljs-keyword">as</span> wavfile

freq, waveform_arr = wavfile.read(<span class="hljs-string">&apos;1-100038-A-14.wav&apos;</span>)
waveform = torch.from_numpy(waveform_arr).float()
</code></pre>
<p><strong>Fourier transform</strong> : converte a signal in the time domain into its frequency content</p>
<p>We import the <code>signal</code> module from SciPy,
then provide the <code>spectrogram</code> function with the waveform and the sampling frequency that we got previously.
The return values are all NumPy arrays, namely frequency <code>f_arr</code> (values along the Y axis), time <code>t_arr</code> (values along the X axis) and the actual spectrogra <code>sp_arr</code> as a 2D array</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> signal

f_arr, t_arr, sp_arr = signal.spectrogram(waveform_arr, freq)

sp_mono = torch.from_numpy(sp_arr)
</code></pre>
<p>Dimensions are <code>F x T</code>, where <code>F</code> is frequency and <code>T</code> is time.</p>
<p>Stack the two tensors along the first dimension to obtain a two channels image of size <code>C x F x T</code>, where <code>C</code> is the number channels:</p>
<pre><code class="lang-python">sp_t = torch.stack((sp_left_t, sp_right_t), dim=<span class="hljs-number">0</span>)
</code></pre>
<h2 id="video">Video</h2>
<p>When it comes to the shape of tensors, video data can be seen as equivalent to volumetric data, with <code>depth</code> replaced by the <code>time</code> dimension. The result is again a 5D tensor with shape <code>N x C x T x H x W</code>.</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> imageio

reader = imageio.get_reader(<span class="hljs-string">&apos;cockatoo.mp4&apos;</span>)
meta = reader.get_meta_data()
n_channels = <span class="hljs-number">3</span>
n_frames = meta[<span class="hljs-string">&apos;nframes&apos;</span>]
video = torch.empty(n_channels, n_frames, *meta[<span class="hljs-string">&apos;size&apos;</span>])
<span class="hljs-keyword">for</span> i, frame_arr <span class="hljs-keyword">in</span> enumerate(reader):
    frame = torch.from_numpy(frame_arr).float()
    video[:, i] = torch.transpose(frame, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)
</code></pre>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="three_kinds_of_data.html" class="navigation navigation-prev " aria-label="Previous page: three kinds of data">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="walking_through_a_learning_algorithm_from_scratch.html" class="navigation navigation-next " aria-label="Next page: The mechanics of learning">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"real world data representation","level":"1.7.3","depth":2,"next":{"title":"The mechanics of learning","level":"1.7.4","depth":2,"path":"pytorch/walking_through_a_learning_algorithm_from_scratch.md","ref":"pytorch/walking_through_a_learning_algorithm_from_scratch.md","articles":[]},"previous":{"title":"three kinds of data","level":"1.7.2","depth":2,"path":"pytorch/three_kinds_of_data.md","ref":"pytorch/three_kinds_of_data.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["mathjax","katex"],"pluginsConfig":{"mathjax":{"forceSVG":false,"version":"2.6-latest"},"katex":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"pytorch/real_data_representaion.md","mtime":"2020-07-20T13:54:09.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2020-07-20T14:05:14.223Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

