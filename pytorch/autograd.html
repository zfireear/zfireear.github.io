
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Backpropagate all things Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="training_validation_overfitting.html" />
    
    
    <link rel="prev" href="walking_through_a_learning_algorithm_from_scratch.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../markdown_math_syntax.html">
            
                <a href="../markdown_math_syntax.html">
            
                    
                    Markdown Math Syntax
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../gradient_descent/gradient_descent.html">
            
                <a href="../gradient_descent/gradient_descent.html">
            
                    
                    Gradient Descent
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../gradient_descent/more_about_gradient_descent.html">
            
                <a href="../gradient_descent/more_about_gradient_descent.html">
            
                    
                    More about Gradient Descent
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../gradient_descent/new_optimization.html">
            
                <a href="../gradient_descent/new_optimization.html">
            
                    
                    New Optimazation
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../classification/classification.html">
            
                <a href="../classification/classification.html">
            
                    
                    Classification
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../logistic_regression/logistic_regression.html">
            
                <a href="../logistic_regression/logistic_regression.html">
            
                    
                    Logistic Regression
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../logistic_regression/lrcode.html">
            
                <a href="../logistic_regression/lrcode.html">
            
                    
                    LRCode
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../deep_learning/deep_learning.html">
            
                <a href="../deep_learning/deep_learning.html">
            
                    
                    Deep Learing
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../deep_learning/tips_for_deep_learning.html">
            
                <a href="../deep_learning/tips_for_deep_learning.html">
            
                    
                    Tips for Deep Learning
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="pytorch.html">
            
                <a href="pytorch.html">
            
                    
                    Pytorch
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="main_mdel_introduction.html">
            
                <a href="main_mdel_introduction.html">
            
                    
                    Main Model Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="three_kinds_of_data.html">
            
                <a href="three_kinds_of_data.html">
            
                    
                    three kinds of data
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.3" data-path="real_data_representaion.html">
            
                <a href="real_data_representaion.html">
            
                    
                    real world data representation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.4" data-path="walking_through_a_learning_algorithm_from_scratch.html">
            
                <a href="walking_through_a_learning_algorithm_from_scratch.html">
            
                    
                    The mechanics of learning
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.7.5" data-path="autograd.html">
            
                <a href="autograd.html">
            
                    
                    Backpropagate all things
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.6" data-path="training_validation_overfitting.html">
            
                <a href="training_validation_overfitting.html">
            
                    
                    Training, validation, and overfitting
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.7" data-path="neural_network.html">
            
                <a href="neural_network.html">
            
                    
                    Neural Network
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.8" data-path="nn_module.html">
            
                <a href="nn_module.html">
            
                    
                    NN Module
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.9" data-path="subclassing_nn_module.html">
            
                <a href="subclassing_nn_module.html">
            
                    
                    Subclassing NN Module
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.10" data-path="pre-trained_network.html">
            
                <a href="pre-trained_network.html">
            
                    
                    Pre-trained Network
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.11" data-path="image_classification.html">
            
                <a href="image_classification.html">
            
                    
                    Image Classification
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.12" data-path="problem_set_of_pytorch.html">
            
                <a href="problem_set_of_pytorch.html">
            
                    
                    Problem Set of PyTorch
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="../convolutional_neural_network/cnn.html">
            
                <a href="../convolutional_neural_network/cnn.html">
            
                    
                    Convolutional Neural network
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.1" data-path="../convolutional_neural_network/cnn_network_structure.html">
            
                <a href="../convolutional_neural_network/cnn_network_structure.html">
            
                    
                    CNN Network Structure
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.2" data-path="../convolutional_neural_network/common_cnn.html">
            
                <a href="../convolutional_neural_network/common_cnn.html">
            
                    
                    Common CNN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.3" data-path="../convolutional_neural_network/cnn_aplication.html">
            
                <a href="../convolutional_neural_network/cnn_aplication.html">
            
                    
                    CNN Aplication
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="../graph_neural_network/graph_neural_network.html">
            
                <a href="../graph_neural_network/graph_neural_network.html">
            
                    
                    Graph Neural Network
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.9.1" data-path="../graph_neural_network/introduce_to_graph_neural_network.html">
            
                <a href="../graph_neural_network/introduce_to_graph_neural_network.html">
            
                    
                    Introduce to Graph Neural Network
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.2" data-path="../graph_neural_network/Spatial_based_gnn.html">
            
                <a href="../graph_neural_network/Spatial_based_gnn.html">
            
                    
                    Spatial-based GNN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.3" data-path="../graph_neural_network/Spectral_based_gnn.html">
            
                <a href="../graph_neural_network/Spectral_based_gnn.html">
            
                    
                    Spectral_based_gnn
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="../recurrent_neural_network/recurrent_neural_network.html">
            
                <a href="../recurrent_neural_network/recurrent_neural_network.html">
            
                    
                    Recurrent Neural Network
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.1" data-path="../recurrent_neural_network/recursive_structure.html">
            
                <a href="../recurrent_neural_network/recursive_structure.html">
            
                    
                    Recursive Structure
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.11" data-path="../semi_supervised/semi_supervised.html">
            
                <a href="../semi_supervised/semi_supervised.html">
            
                    
                    Semi-supervised
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12" data-path="../word_embedding/word_embedding.html">
            
                <a href="../word_embedding/word_embedding.html">
            
                    
                    Word Embedding
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.13" data-path="../explainable_machine_learning/explainable_machine_learning.html">
            
                <a href="../explainable_machine_learning/explainable_machine_learning.html">
            
                    
                    Explainable Machine Learning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.14" data-path="../attack_ml_models/attack_ml_models.html">
            
                <a href="../attack_ml_models/attack_ml_models.html">
            
                    
                    Attack ML Models
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.14.1" data-path="../attack_ml_models/attack_image_and_audio.html">
            
                <a href="../attack_ml_models/attack_image_and_audio.html">
            
                    
                    Attack image and audio
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.15" data-path="../network_compression/network_compression.html">
            
                <a href="../network_compression/network_compression.html">
            
                    
                    Network Compression
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.15.1" data-path="../network_compression/knowledge_distillation.html">
            
                <a href="../network_compression/knowledge_distillation.html">
            
                    
                    Knowledge Distillation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.2" data-path="../network_compression/network_pruning.html">
            
                <a href="../network_compression/network_pruning.html">
            
                    
                    Network Pruning
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.16" data-path="../transformer/transformer.html">
            
                <a href="../transformer/transformer.html">
            
                    
                    Transformer
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.16.1" data-path="../transformer/variant_of_transformers.html">
            
                <a href="../transformer/variant_of_transformers.html">
            
                    
                    Variant of Transformers
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.17" data-path="../conditional_generation_by_RNN_&_Attention/conditional_generation_by_RNN_&_Attention.html">
            
                <a href="../conditional_generation_by_RNN_&_Attention/conditional_generation_by_RNN_&_Attention.html">
            
                    
                    Conditional Generation by RNN & Attention
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.18" data-path="../unsupervised_learning/unsupervised_learning.html">
            
                <a href="../unsupervised_learning/unsupervised_learning.html">
            
                    
                    Unsupervised Learning
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.18.1" data-path="../unsupervised_learning/dimension_reduction.html">
            
                <a href="../unsupervised_learning/dimension_reduction.html">
            
                    
                    Dimension Reduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.18.2" data-path="../unsupervised_learning/neighbor_embedding.html">
            
                <a href="../unsupervised_learning/neighbor_embedding.html">
            
                    
                    Neighbor Embedding
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.18.3" data-path="../unsupervised_learning/deep_auto_encoder.html">
            
                <a href="../unsupervised_learning/deep_auto_encoder.html">
            
                    
                    Deep Auto-encoder
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.19" data-path="../bert_and_its_family/bert_and_its_family.html">
            
                <a href="../bert_and_its_family/bert_and_its_family.html">
            
                    
                    Bert and its Family
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.19.1" data-path="../bert_and_its_family/bert.html">
            
                <a href="../bert_and_its_family/bert.html">
            
                    
                    Bert
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.20" data-path="../nlp/natural_language_processing.html">
            
                <a href="../nlp/natural_language_processing.html">
            
                    
                    Natual Language Processing
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.20.1" data-path="../nlp/introduction.html">
            
                <a href="../nlp/introduction.html">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.21" data-path="../anomaly_detection/anomaly_detection.html">
            
                <a href="../anomaly_detection/anomaly_detection.html">
            
                    
                    Anomaly Detection
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Backpropagate all things</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="backpropagate-all-things">Backpropagate all things</h1>
<p>Gradient ,which we called <code>the rate of change of the loss</code> earlier.</p>
<p>PyTorch tensors can remember where they come from in terms of the operations and parent tensors that originated them, and they can provide the chain of derivatives of such operations with respect to their inputs automatically. Given a forward expression, PyTorch  provides  the  gradient  of  that expression  with  respect  to  its  inputparameters automatically.</p>
<pre><code class="lang-python">params = torch.tensor([<span class="hljs-number">1.0</span>, <span class="hljs-number">0.0</span>], requires_grad=<span class="hljs-keyword">True</span>)
</code></pre>
<p><strong>In general, all PyTorch tensors have an attribute named <code>grad</code>, normally None.</strong></p>
<p><strong>Calling <code>backward</code> leads derivatives to accumulate at leaf nodes. You need to zero the gradient explicitly after using it for parameter updates.</strong>  </p>
<p>The gradient at each leaf is accumulated (summed) on top of the one computed at the preceding iteration. So you need zero the gradient explicitly at each iteration by using the in-place <code>zero_</code> method, which could be done at any point in the loop prior to calling <code>loss.backward()</code></p>
<pre><code class="lang-python"><span class="hljs-keyword">if</span> params.grad <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
    params.grad.zero_()
</code></pre>
<p>Detach the new params tensor from the computation  graph  associatedwith its update expression by calling <code>.detatch()</code>  </p>
<p>You can reenable tracking by calling <code>.requires_grad_()</code>,  an <code>in_place</code> operation (see the trailing _) that reactivates autograd for the  tensor. At that time, you can release the memory held by old versions of params and need to backpropagate through only your current weights.</p>
<p><strong>NOTE</strong> The usage of <code>.detach()</code> is more secure</p>
<pre><code class="lang-python"><span class="hljs-comment"># Q: What is the value of  x  that minimizes  f ?</span>
x = torch.tensor([<span class="hljs-number">5.0</span>],requires_grad=<span class="hljs-keyword">True</span>)
step_size = <span class="hljs-number">0.25</span>
print(<span class="hljs-string">&quot;iter,\tx,\tf(x),\tf\&apos;(x),\tf\&apos;(x) pytorch&quot;</span>)
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">15</span>):
    y = f(x)
    y.backward()

    print(<span class="hljs-string">&quot;{},\t{:.3f},\t{:.3f},\t{:.3f},\t{:.3f}&quot;</span>.format(
            i,x.item(),f(x).item(),fp(x).item(),x.grad.item()))
    <span class="hljs-comment"># .data &#x548C;.detach&#x53EA;&#x53D6;&#x51FA;&#x672C;&#x4F53;tensor&#x6570;&#x636E;&#xFF0C;&#x820D;&#x5F03;&#x4E86;grad&#xFF0C;grad_fn&#x7B49;&#x989D;&#x5916;&#x53CD;&#x5411;&#x56FE;&#x8BA1;&#x7B97;&#x8FC7;&#x7A0B;&#x9700;&#x4FDD;&#x5B58;&#x7684;&#x989D;&#x5916;&#x4FE1;&#x606F;&#x3002;</span>
    <span class="hljs-comment"># The .data and .detach operation only withdraw ontological data from tensor, and discard the extra information that needs to be saved in the calculation process of back propagation such as grad and grad_fn.</span>
    x.data = x.data - step_size*x.grad
    <span class="hljs-comment"># zero the grad</span>
    <span class="hljs-comment"># the detach_() is for efficiency</span>
    x.grad.detach_()
    x.grad.zero_()
    <span class="hljs-comment">#print(x.data) </span>
    <span class="hljs-comment">#.data&#x53D6;&#x51FA;&#x672C;&#x4F53;tensor&#x540E;&#x4ECD;&#x4E0E;&#x539F;&#x6570;&#x636E;&#x5171;&#x4EAB;&#x5185;&#x5B58;&#xFF0C;&#x5728;&#x4F7F;&#x7528;in-place&#x64CD;&#x4F5C;&#x540E;&#xFF0C;&#x4F1A;&#x4FEE;&#x6539;&#x539F;&#x6570;&#x636E;&#x7684;&#x503C;&#xFF0C;</span>
    <span class="hljs-comment">#&#x800C;&#x5982;&#x679C;&#x5728;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x8FC7;&#x7A0B;&#x4E2D;&#x4F7F;&#x7528;&#x5230;&#x539F;&#x6570;&#x636E;&#x4F1A;&#x5BFC;&#x81F4;&#x8BA1;&#x7B97;&#x9519;&#x8BEF;&#xFF0C;&#x800C;&#x4F7F;&#x7528;.detach&#x540E;&#xFF0C;&#x5982;&#x679C;&#x5728;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x8FC7;&#x7A0B;&#x4E2D;&#x53D1;&#x73B0;&#x539F;&#x6570;&#x636E;&#x88AB;&#x4FEE;&#x6539;&#x8FC7;&#x4F1A;&#x62A5;&#x9519;&#x3002;&#x66F4;&#x52A0;&#x5B89;&#x5168;</span>
    <span class="hljs-comment"># The .data operation takes out the ontology tensor and still shares memory with the original data, which the value of the original data will be modified after using the in-place operation</span>
    <span class="hljs-comment"># If the original data is used in the process of back propagation, it will cause calculation errors. After using .detach operation, if the original data had been modified in the process of back propagation, an error will be reported. It results in safer checking.</span>
</code></pre>
<h2 id="demo-of-pytorchs-autograd">Demo of Pytorch&apos;s autograd</h2>
<pre><code class="lang-python"><span class="hljs-comment"># Prepare the data</span>
t_c = [<span class="hljs-number">0.5</span>,  <span class="hljs-number">14.0</span>, <span class="hljs-number">15.0</span>, <span class="hljs-number">28.0</span>, <span class="hljs-number">11.0</span>,  <span class="hljs-number">8.0</span>,  <span class="hljs-number">3.0</span>, <span class="hljs-number">-4.0</span>,  <span class="hljs-number">6.0</span>, <span class="hljs-number">13.0</span>, <span class="hljs-number">21.0</span>]
t_u = [<span class="hljs-number">35.7</span>, <span class="hljs-number">55.9</span>, <span class="hljs-number">58.2</span>, <span class="hljs-number">81.9</span>, <span class="hljs-number">56.3</span>, <span class="hljs-number">48.9</span>, <span class="hljs-number">33.9</span>, <span class="hljs-number">21.8</span>, <span class="hljs-number">48.4</span>, <span class="hljs-number">60.4</span>, <span class="hljs-number">68.4</span>]
t_c = torch.tensor(t_c)
t_u = torch.tensor(t_u)
t_un = t_u * <span class="hljs-number">0.1</span>

<span class="hljs-comment"># definition of model</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">model</span><span class="hljs-params">(t_u,w,b)</span>:</span>
    <span class="hljs-keyword">return</span> w * t_u + b

<span class="hljs-comment"># definition of loss function</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">loss_fn</span><span class="hljs-params">(t_p,t_c)</span>:</span>
    squared_diffs = (t_p - t_c)**<span class="hljs-number">2</span>
    <span class="hljs-keyword">return</span> squared_diffs.mean()

<span class="hljs-comment"># training using pytorch&apos;s autograd </span>
<span class="hljs-comment"># update params with grad</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">training_loop</span><span class="hljs-params">(n_epochs,learning_rate,params,t_u,t_c)</span>:</span>
    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>,n_epochs + <span class="hljs-number">1</span>):
        <span class="hljs-keyword">if</span> params.grad <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
            params.grad.zero_()
        t_p = model(t_u,*params)
        loss = loss_fn(t_p,t_c)
        loss.backward()
        params = (params - learning_rate * params.grad).detach().requires_grad_()    
    <span class="hljs-keyword">return</span> params

loss = loss_fn(model(t_u,*params),t_c)
loss.backward()

training_loop(
    n_epochs = <span class="hljs-number">5000</span>,
    learning_rate = <span class="hljs-number">1e-2</span>,
    params = torch.tensor([<span class="hljs-number">1.0</span>,<span class="hljs-number">0.0</span>],requires_grad=<span class="hljs-keyword">True</span>),
    t_u = t_un,
    t_c = t_c
)
</code></pre>
<h2 id="optimizer">Optimizer</h2>
<p>The <code>torch</code> module has an <code>optim</code> submodule where you can find classes that implement different optimization algorithms. </p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim

dir(optim)

<span class="hljs-comment"># output:</span>
 [<span class="hljs-string">&apos;ASGD&apos;</span>,  
 <span class="hljs-string">&apos;Adadelta&apos;</span>,
 <span class="hljs-string">&apos;Adagrad&apos;</span>,
 <span class="hljs-string">&apos;Adam&apos;</span>,
 <span class="hljs-string">&apos;AdamW&apos;</span>,
 <span class="hljs-string">&apos;Adamax&apos;</span>,
 <span class="hljs-string">&apos;LBFGS&apos;</span>,
 <span class="hljs-string">&apos;Optimizer&apos;</span>,
 <span class="hljs-string">&apos;RMSprop&apos;</span>,
 <span class="hljs-string">&apos;Rprop&apos;</span>,
 <span class="hljs-string">&apos;SGD&apos;</span>]
</code></pre>
<p>Every optimizer constructor takes a list of parameters (aka PyTorch tensors, typically with <code>requires_grad</code> set to <code>True</code>) as the first input.  </p>
<pre><code class="lang-python">params = torch.tensor([<span class="hljs-number">1.0</span>,<span class="hljs-number">0.0</span>],requires_grad=<span class="hljs-keyword">True</span>)
learning_rate = <span class="hljs-number">1e-2</span>
optimizer = optim.SGD([params],lr=learning_rate)
</code></pre>
<p>All parameters passed to the optimizer are retained inside the optimizer object so that the optimizer can update their values and access their <code>grad</code> attribute.</p>
<p>Each optimizer exposes two methods: <code>zero_grad</code> and <code>step</code>. The former zeros the grad attribute of all the parameters passed to the optimizer upon construction. The latter updates the value of those parameters according to the optimization strategy implemented by the specific optimizer.</p>
<pre><code class="lang-python">t_p = model(t_u,*params)
loss = loss_fn(t_p,t_c)
optimizer.zero_grad()
loss.backward()
optimizer.step()
</code></pre>
<p>Optimizer <code>Adam</code> in which the learning rate is set adaptivel is a lot less sensitive to the scaling of the parameters.</p>
<pre><code class="lang-python">params = torch.tensor([<span class="hljs-number">1.0</span>,<span class="hljs-number">0.0</span>],requires_grad=<span class="hljs-keyword">True</span>)
learning_rate = <span class="hljs-number">1e-1</span>
optimizer = optim.Adam([params],lr=learning_rate)
</code></pre>
<p>Neural networks allow you to remove your arbitrary assumptions about the shape of the function you should be approximating.</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="walking_through_a_learning_algorithm_from_scratch.html" class="navigation navigation-prev " aria-label="Previous page: The mechanics of learning">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="training_validation_overfitting.html" class="navigation navigation-next " aria-label="Next page: Training, validation, and overfitting">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Backpropagate all things","level":"1.7.5","depth":2,"next":{"title":"Training, validation, and overfitting","level":"1.7.6","depth":2,"path":"pytorch/training_validation_overfitting.md","ref":"pytorch/training_validation_overfitting.md","articles":[]},"previous":{"title":"The mechanics of learning","level":"1.7.4","depth":2,"path":"pytorch/walking_through_a_learning_algorithm_from_scratch.md","ref":"pytorch/walking_through_a_learning_algorithm_from_scratch.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["mathjax","katex"],"pluginsConfig":{"mathjax":{"forceSVG":false,"version":"2.6-latest"},"katex":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"pytorch/autograd.md","mtime":"2020-07-20T13:54:09.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2020-07-20T14:05:14.223Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

