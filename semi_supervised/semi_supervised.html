
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Semi-supervised Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../word_embedding/word_embedding.html" />
    
    
    <link rel="prev" href="../recurrent_neural_network/recursive_structure.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../markdown_math_syntax.html">
            
                <a href="../markdown_math_syntax.html">
            
                    
                    Markdown Math Syntax
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../gradient_descent/gradient_descent.html">
            
                <a href="../gradient_descent/gradient_descent.html">
            
                    
                    Gradient Descent
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../gradient_descent/more_about_gradient_descent.html">
            
                <a href="../gradient_descent/more_about_gradient_descent.html">
            
                    
                    More about Gradient Descent
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../gradient_descent/new_optimization.html">
            
                <a href="../gradient_descent/new_optimization.html">
            
                    
                    New Optimazation
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../classification/classification.html">
            
                <a href="../classification/classification.html">
            
                    
                    Classification
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../logistic_regression/logistic_regression.html">
            
                <a href="../logistic_regression/logistic_regression.html">
            
                    
                    Logistic Regression
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../logistic_regression/lrcode.html">
            
                <a href="../logistic_regression/lrcode.html">
            
                    
                    LRCode
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../deep_learning/deep_learning.html">
            
                <a href="../deep_learning/deep_learning.html">
            
                    
                    Deep Learing
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../deep_learning/tips_for_deep_learning.html">
            
                <a href="../deep_learning/tips_for_deep_learning.html">
            
                    
                    Tips for Deep Learning
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="../pytorch/pytorch.html">
            
                <a href="../pytorch/pytorch.html">
            
                    
                    Pytorch
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="../pytorch/main_mdel_introduction.html">
            
                <a href="../pytorch/main_mdel_introduction.html">
            
                    
                    Main Model Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="../pytorch/three_kinds_of_data.html">
            
                <a href="../pytorch/three_kinds_of_data.html">
            
                    
                    three kinds of data
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.3" data-path="../pytorch/real_data_representaion.html">
            
                <a href="../pytorch/real_data_representaion.html">
            
                    
                    real world data representation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.4" data-path="../pytorch/walking_through_a_learning_algorithm_from_scratch.html">
            
                <a href="../pytorch/walking_through_a_learning_algorithm_from_scratch.html">
            
                    
                    The mechanics of learning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.5" data-path="../pytorch/autograd.html">
            
                <a href="../pytorch/autograd.html">
            
                    
                    Backpropagate all things
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.6" data-path="../pytorch/training_validation_overfitting.html">
            
                <a href="../pytorch/training_validation_overfitting.html">
            
                    
                    Training, validation, and overfitting
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.7" data-path="../pytorch/neural_network.html">
            
                <a href="../pytorch/neural_network.html">
            
                    
                    Neural Network
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.8" data-path="../pytorch/nn_module.html">
            
                <a href="../pytorch/nn_module.html">
            
                    
                    NN Module
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.9" data-path="../pytorch/subclassing_nn_module.html">
            
                <a href="../pytorch/subclassing_nn_module.html">
            
                    
                    Subclassing NN Module
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.10" data-path="../pytorch/pre-trained_network.html">
            
                <a href="../pytorch/pre-trained_network.html">
            
                    
                    Pre-trained Network
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.11" data-path="../pytorch/image_classification.html">
            
                <a href="../pytorch/image_classification.html">
            
                    
                    Image Classification
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.12" data-path="../pytorch/problem_set_of_pytorch.html">
            
                <a href="../pytorch/problem_set_of_pytorch.html">
            
                    
                    Problem Set of PyTorch
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="../convolutional_neural_network/cnn.html">
            
                <a href="../convolutional_neural_network/cnn.html">
            
                    
                    Convolutional Neural network
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.1" data-path="../convolutional_neural_network/cnn_network_structure.html">
            
                <a href="../convolutional_neural_network/cnn_network_structure.html">
            
                    
                    CNN Network Structure
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.2" data-path="../convolutional_neural_network/common_cnn.html">
            
                <a href="../convolutional_neural_network/common_cnn.html">
            
                    
                    Common CNN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.3" data-path="../convolutional_neural_network/cnn_aplication.html">
            
                <a href="../convolutional_neural_network/cnn_aplication.html">
            
                    
                    CNN Aplication
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="../graph_neural_network/graph_neural_network.html">
            
                <a href="../graph_neural_network/graph_neural_network.html">
            
                    
                    Graph Neural Network
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.9.1" data-path="../graph_neural_network/introduce_to_graph_neural_network.html">
            
                <a href="../graph_neural_network/introduce_to_graph_neural_network.html">
            
                    
                    Introduce to Graph Neural Network
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.2" data-path="../graph_neural_network/Spatial_based_gnn.html">
            
                <a href="../graph_neural_network/Spatial_based_gnn.html">
            
                    
                    Spatial-based GNN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.3" data-path="../graph_neural_network/Spectral_based_gnn.html">
            
                <a href="../graph_neural_network/Spectral_based_gnn.html">
            
                    
                    Spectral_based_gnn
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="../recurrent_neural_network/recurrent_neural_network.html">
            
                <a href="../recurrent_neural_network/recurrent_neural_network.html">
            
                    
                    Recurrent Neural Network
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.1" data-path="../recurrent_neural_network/recursive_structure.html">
            
                <a href="../recurrent_neural_network/recursive_structure.html">
            
                    
                    Recursive Structure
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter active" data-level="1.11" data-path="semi_supervised.html">
            
                <a href="semi_supervised.html">
            
                    
                    Semi-supervised
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12" data-path="../word_embedding/word_embedding.html">
            
                <a href="../word_embedding/word_embedding.html">
            
                    
                    Word Embedding
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.13" data-path="../explainable_machine_learning/explainable_machine_learning.html">
            
                <a href="../explainable_machine_learning/explainable_machine_learning.html">
            
                    
                    Explainable Machine Learning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.14" data-path="../attack_ml_models/attack_ml_models.html">
            
                <a href="../attack_ml_models/attack_ml_models.html">
            
                    
                    Attack ML Models
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.14.1" data-path="../attack_ml_models/attack_image_and_audio.html">
            
                <a href="../attack_ml_models/attack_image_and_audio.html">
            
                    
                    Attack image and audio
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.15" data-path="../network_compression/network_compression.html">
            
                <a href="../network_compression/network_compression.html">
            
                    
                    Network Compression
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.15.1" data-path="../network_compression/knowledge_distillation.html">
            
                <a href="../network_compression/knowledge_distillation.html">
            
                    
                    Knowledge Distillation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15.2" data-path="../network_compression/network_pruning.html">
            
                <a href="../network_compression/network_pruning.html">
            
                    
                    Network Pruning
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.16" data-path="../transformer/transformer.html">
            
                <a href="../transformer/transformer.html">
            
                    
                    Transformer
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.16.1" data-path="../transformer/variant_of_transformers.html">
            
                <a href="../transformer/variant_of_transformers.html">
            
                    
                    Variant of Transformers
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.17" data-path="../conditional_generation_by_RNN_&_Attention/conditional_generation_by_RNN_&_Attention.html">
            
                <a href="../conditional_generation_by_RNN_&_Attention/conditional_generation_by_RNN_&_Attention.html">
            
                    
                    Conditional Generation by RNN & Attention
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.18" data-path="../unsupervised_learning/unsupervised_learning.html">
            
                <a href="../unsupervised_learning/unsupervised_learning.html">
            
                    
                    Unsupervised Learning
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.18.1" data-path="../unsupervised_learning/dimension_reduction.html">
            
                <a href="../unsupervised_learning/dimension_reduction.html">
            
                    
                    Dimension Reduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.18.2" data-path="../unsupervised_learning/neighbor_embedding.html">
            
                <a href="../unsupervised_learning/neighbor_embedding.html">
            
                    
                    Neighbor Embedding
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.18.3" data-path="../unsupervised_learning/deep_auto_encoder.html">
            
                <a href="../unsupervised_learning/deep_auto_encoder.html">
            
                    
                    Deep Auto-encoder
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.19" data-path="../bert_and_its_family/bert_and_its_family.html">
            
                <a href="../bert_and_its_family/bert_and_its_family.html">
            
                    
                    Bert and its Family
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.19.1" data-path="../bert_and_its_family/bert.html">
            
                <a href="../bert_and_its_family/bert.html">
            
                    
                    Bert
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.20" data-path="../nlp/natural_language_processing.html">
            
                <a href="../nlp/natural_language_processing.html">
            
                    
                    Natual Language Processing
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.20.1" data-path="../nlp/introduction.html">
            
                <a href="../nlp/introduction.html">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.21" data-path="../anomaly_detection/anomaly_detection.html">
            
                <a href="../anomaly_detection/anomaly_detection.html">
            
                    
                    Anomaly Detection
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Semi-supervised</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="semi-supervised">Semi-supervised</h1>
<h2 id="introduction">Introduction</h2>
<ul>
<li>Supervised Learning : $\lbrace (x^r,\hat{y}^r) \rbrace_{r=1}^R$<ul>
<li>E.g. $x^r$ : image,$\hat{y}^r$ : class labels</li>
</ul>
</li>
<li>Semi-supervised learning : $\lbrace (x^r,\hat{y}^r) \rbrace<em>{r=1}^R$,$\lbrace x^u\rbrace</em>{u=R}^{R+U}$<ul>
<li>A set of unlabeled data,usually U  $\gg$ R</li>
<li>Transductive learning : unlabeled data  is the testing data, but trained with its features.</li>
<li>Inductive learning : unlabeled data is not the testing data, which need train a model firstly.</li>
</ul>
</li>
<li>Why semi-supervised learning?<ul>
<li>Collecting data is easy, but collecting &quot;labeled&quot; data is expensive</li>
<li>We do semi-supervised learning in our lives</li>
</ul>
</li>
</ul>
<h3 id="why-semi-supervised-learning-helps">Why semi-supervised learning helps?</h3>
<p>The distribution of the unlabeled data tell us something usually with some assumptions. The assumption greatly influences the effect of model.  </p>
<h2 id="semi-supervised-learning-for-generative-model">Semi-supervised Learning for Generative Model</h2>
<h3 id="supervised-generative-model">Supervised Generative Model</h3>
<ul>
<li>Given labelled training examples $x^r \in C_1,C_2$<ul>
<li>Looking for most likely prior probability $P(C_i)$ and class-dependent probability $P(x|C_i)$</li>
<li>$P(x|C_i)$ is a Gaussian parameterized by $\mu^i$ and $\Sigma$  </li>
</ul>
</li>
</ul>
<p>With $P(C_1),P(C_2),\mu^1,\mu^2,\Sigma$ : 
<script type="math/tex; ">P(C_1|x) = \dfrac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1)+P(x|C_2)P(C_2)}</script></p>
<h3 id="semi-supervised-generative-model">Semi-supervised Generative Model</h3>
<ul>
<li>Given labelled training example $x^r \in C_1,C_2$<ul>
<li>Looking for most likely prior probability $P(C_i)$ and class-dependent probability $P(x|C_i)$</li>
<li>$P(x|C_i)$ is a Gaussian parameterized by $\mu^i$ and $\Sigma$</li>
</ul>
</li>
</ul>
<p>The unlabeled data $x^u$ help re-estimate $P(C_1),P(C_2),\mu^1,\mu^2,\Sigma$</p>
<ul>
<li>Initialization : $\theta = \lbrace P(C_1),P(C_2),\mu^1,\mu^2,\Sigma\rbrace$</li>
<li>Step 1 : compute the posterior probability of unlabeled data $P_\theta(C_1|x^u)$, depending on model $\theta$</li>
<li>Step 2 : update model<br>N : total number of examples<br>$N_1$ : number of examples belonging to $C_1$</li>
</ul>
<p><script type="math/tex; ">P(C_1) = \dfrac{N_1+\sum_{x^u}P(C_1|x^u)}{N}</script>
<script type="math/tex; ">\mu^1 = \frac{1}{N_1}\sum_{x^r \in C_1}x^r + \dfrac{1}{\sum_{x^u}P(C_1|x^u)}\sum_{x^u}P(C_1|x^u)x^u</script></p>
<ul>
<li>Back to step 1</li>
</ul>
<p>The unlabeled data can tell us how many times $C_1$ occurs. The number of occurrences of $C_1$ is the sum of posterior probability of $C_1$ within all unlabeled data. The unlabeled data is not hard design, saying it must belong to $C_1$ or $C_2$, but depends on its posterior probability. We say what percentage of unlabeled data belongs to $C_1$ and what percentage belongs to $C_2$. Thus we can calculate prior probability of $C_1$ according to unsupervised data which affects your estimate of $C_1$.</p>
<p>The algorithm converges eventually, but the initialization influences the results.</p>
<h3 id="math-principle">Math principle</h3>
<p>$\theta = \lbrace P(C_1),P(C_2),\mu^1,\mu^2,\Sigma\rbrace$</p>
<ul>
<li>Maximum likelihood with labeled data (Closed-form solution)
<script type="math/tex; ">\log L(\theta) = \sum_{x^r}\log P_\theta(x^r,\hat{y}^r)</script>
<script type="math/tex; ">P_\theta(x^r,\hat{y}^r) = P_\theta(x^r|\hat{y}^r)P(\hat{y}^r)</script></li>
<li>Maximum likelihood with labeled + unlabeled data(Solved iteratively)  </li>
</ul>
<p><script type="math/tex; ">\log L(\theta) = \sum_{x^r}\log P_\theta(x^r,\hat{y}^r) + \sum_{x^u}\log P_\theta(x^u)</script>
<script type="math/tex; ">P_\theta(x^u) = P_\theta(x^u|C_1)P(C_1) + P_\theta(x^u|C_2)P(C_2)</script></p>
<p>$x^u$ can come from either $C_1$ and $C_2$</p>
<h2 id="semi-supervised-learning-low-density-separation">Semi-supervised Learning Low-density Separation</h2>
<blockquote>
<p>Low-density separation : Black-or-White</p>
<h3 id="self-training">Self-training</h3>
<ul>
<li>Given: labeled data set $\lbrace (x^r,\hat{y}^r) \rbrace<em>{r=1}^R$, unlabeled data set $\lbrace x^u \rbrace</em>{u=l}^{R+U}$</li>
<li>Repeat:<ul>
<li>Train model $f*$ from labelled data set <ul>
<li>Independent to the model </li>
<li>Not for regression</li>
</ul>
</li>
<li>Apply $f*$ to the unlabeled data set<ul>
<li>Obtain $\lbrace (x^u,y^u) \rbrace_{u=l}^{R+U}$ (Pseudo-label)</li>
</ul>
</li>
<li>Remove a set of data from unlabeled data set, and add them into the labeled data set<ul>
<li>You can also provide a weight to each data.</li>
</ul>
</li>
</ul>
</li>
</ul>
</blockquote>
<ul>
<li>Similar to semi-supervised learning for generative model</li>
<li>Hard label v.s. Soft label<ul>
<li>self-training(hard label): force to assign a piece of training data to a certain category.</li>
<li>Generative model(soft label): classification based on posterior probability. Some belong to class 1, others belong to class 2.<br>For neural network, soft label makes no sence. You have to use hard label, which is low-density separation assumption.</li>
</ul>
</li>
</ul>
<h3 id="entropy-based-regularization">Entropy-based Regularization</h3>
<p><script type="math/tex; ">x^u \rightarrow \theta^* \rightarrow y^u</script>
When you use neural network, the output is a distribution. We don&apos;t have to draw a arbitrary conclusion, such as saying the output belongs to which class. But the distribution had better become very concentrated.<br>Entropy of $y^u$ : evaluate how concentrate the distribution $y^u$ is.
<script type="math/tex; ">E(y^u) = - \sum_{m=1}^ny_m^u\ln (y_m^u)</script>
The entropy $E(y^u)$ has to be as small as possible.<br><strong>Loss Function</strong>:
<script type="math/tex; ">L = \sum_{x^r} C(y^r,\hat{y}^r) + \lambda\sum_{x^u}E(y^u)</script></p>
<h2 id="outlook-semi-supervised-svm">Outlook: Semi-supervised SVM</h2>
<p>Enumerate all possible labels for the unlabeled data. Find a boundary that can provide the largest margin and least erro.</p>
<h2 id="semi-supervised-learning-smoothness-assumption">Semi-supervised Learning Smoothness Assumption</h2>
<blockquote>
<p>You are known by the company you keep</p>
</blockquote>
<ul>
<li>Assumption : &quot;similar&quot; <code>x</code> has the same $\hat{y}$</li>
<li>More precisely:<ul>
<li><code>x</code> is not uniform</li>
<li>If $x^1$ and $x^2$ are close in a high density region. $\hat{y}^1$ and $\hat{y}^2$ are the same.(connected by high density path)</li>
</ul>
</li>
</ul>
<p><strong>smooth assumption</strong> : The two samples have a certain form of transition to make them similar.  </p>
<h2 id="graph-based-approach">Graph-based Approach</h2>
<blockquote>
<p>How to know $x^1$ and $x^2$ are close in a high density region(connected by a high density path)</p>
</blockquote>
<p>Represented the data points as a graph. Graph representation is nature sometimes. </p>
<h3 id="graph-construction">Graph Construction</h3>
<ul>
<li>Define the similarity $s(x^i,x^j)$ between $x^i$ and $x^j$</li>
<li>Add edge:<ul>
<li>K Nearest Neighbor</li>
<li>e-Neighborhood</li>
</ul>
</li>
<li>Edge weight is proportional to $s(x^i,x^j)$<br>Gaussian Radial Basis Function:
<script type="math/tex; ">s(x^i,x^j) = \exp(-\gamma\left\|x^i- x^j\right\|_2^2)</script>
$\left|x^i- x^j\right|_2^2$ can be seen as the squared Euclidean distance between two feature vectors.  </li>
</ul>
<p>Because the value of the RBF kernel function decreases with increasing distance and is between 0 (limit) and 1 (when $x^i$ = $x^j$), it is a ready-made similarity measure representation.</p>
<h3 id="grbf">GRBF</h3>
<p>Why to use this kind of function? Because its rate of decline is fast for it takes exponential operation. Only when two points are extremely closed, their similarity will be great. If only just a little bit further away, similarity will decline quickly, and become small. In other words, each data point on the graph only connected to very close data point, and ignore data points where are a slightly further away. So connected data points have possiblely same class.</p>
<p><strong>Construct the graph</strong> : Calculate similarity between each data point <code>x</code> and bulid intermediate edges.  </p>
<p>Given two points, when they were connected on this graph, They can be considered as the same category. </p>
<ul>
<li>The labeled data influence their neighbors</li>
<li>Propagate through the graph</li>
</ul>
<h3 id="graph-based-approach">Graph-based Approach</h3>
<ul>
<li><p>Define the smoothness of the labels on the graph
<script type="math/tex; ">S = \frac{1}{2}\sum_{i,j}w_{i,j}\times(y^i-y_j)</script>
This definition is for all data(no matter   labeled or not)<br>Smaller means smoother</p>
</li>
<li><p>Redefine the smoothness of the labels on the graph
<script type="math/tex; ">S = \frac{1}{2}\sum_{i,j}w_{i,j}\times(y^i-y_j)=Y^TLY</script>
Y : (R+U)-dim vector
<script type="math/tex; ">Y = [\cdots y^i \cdots y^j \cdots]^T</script>
$L : (R+U)\times (R+U) matrix$ (Graph Laplacian)
<script type="math/tex; ">L = D - W</script></p>
</li>
<li>Loss Function:
<script type="math/tex; ">L = \sum_{x^r}C(y^r,\hat{y}^r) + \lambda S</script></li>
</ul>
<p>Label $Y$ depends on network parameter. So in order to add information of graph into training, you can add smoothness item,which make your label outputed from labeled and unlabeled data fit with smoothness assumption. </p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="../recurrent_neural_network/recursive_structure.html" class="navigation navigation-prev " aria-label="Previous page: Recursive Structure">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../word_embedding/word_embedding.html" class="navigation navigation-next " aria-label="Next page: Word Embedding">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Semi-supervised","level":"1.11","depth":1,"next":{"title":"Word Embedding","level":"1.12","depth":1,"path":"word_embedding/word_embedding.md","ref":"word_embedding/word_embedding.md","articles":[]},"previous":{"title":"Recursive Structure","level":"1.10.1","depth":2,"path":"recurrent_neural_network/recursive_structure.md","ref":"recurrent_neural_network/recursive_structure.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["mathjax","katex"],"pluginsConfig":{"mathjax":{"forceSVG":false,"version":"2.6-latest"},"katex":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"semi_supervised/semi_supervised.md","mtime":"2020-07-20T13:54:09.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2020-07-20T14:05:14.223Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

